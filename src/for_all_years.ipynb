{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e4aaea0-a910-4a3e-8abd-f6e29eb52a1c",
   "metadata": {},
   "source": [
    "# Walkable Accessibility Score for Years 1997 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "568a43f8-246c-4f68-a3bb-35ed55a06e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this cell to time how long it takes to run the notebook\n",
    "\n",
    "import timeit\n",
    "start_time = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb916934-c6a3-4082-b3be-16aecc13f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(1, '/users/ifarah/appdata/roaming/python/python39/site-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63adbb9-8811-47b3-b6de-6fb335954b8c",
   "metadata": {},
   "source": [
    "We must specify the correct directory path to load some packages. In the code below, REPLACE 'ifarah' with your personal username. It should be shown in the output directories of the installed packages above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0badfdb7-6f98-42ba-9256-e803dce0c7bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load libraries -- Takes 1.30 min approx\n",
    "from sklearn.neighbors import BallTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from scipy import stats # for correlation\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111d305f-4d35-4645-9b30-5e67dbc7fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only have to read once\n",
    "# Read in the 2015 Block Group Shapefile for all the US.\n",
    "s_v = gpd.read_file('../data/2015_US_BG/BG_mainland.shp') # Load geography (oftentimes as shapefile).\n",
    "\n",
    "# Add 2011 GreatSchools school data\n",
    "sch = gpd.read_file('../data/GreatSchools_2011_us48/GreatSchools_2011_us48.shp') \n",
    "sch = sch.to_crs('esri:102003')\n",
    "\n",
    "#2021 ESRI parks data (centroids)\n",
    "prk = gpd.read_file('../data/Centroids_for_USA_Parks_2021/parks.shp') \n",
    "prk = prk.to_crs('esri:102003')\n",
    "\n",
    "# Change the Coordinate Reference System\n",
    "s_v = s_v.set_crs('esri:102003', allow_override=True) # Set the Coordinate Reference System\n",
    "s_v.rename(columns={'GEOID': 'ID'}, inplace=True) # Rename the columns for convenience\n",
    "\n",
    "# Extract the centroids of the polygons.\n",
    "# Replace the column \"geometry\" with the centroids of geography.\n",
    "# This will change the geometry from \"polygon\" to \"point\" geometry.\n",
    "s_v['geometry'] = s_v.centroid\n",
    "\n",
    "s_v_filtered = s_v[['ID', 'geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336fc330-ce51-457d-b2c2-70bd5c9cc6d1",
   "metadata": {},
   "source": [
    "## Create functions to run the walkable accessibility score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b929c6c8-7c48-4311-a364-f9b106b62129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is creating a function for eastimating nearest neighbors from point to point.\n",
    "def get_nearest_neighbors(gdf1, gdf2, k_neighbors=2):\n",
    "    '''Find k nearest neighbors for all source points from a set of candidate points\n",
    "    modified from: https://automating-gis-processes.github.io/site/notebooks/L3/nearest-neighbor-faster.html    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf1 : geopandas.DataFrame\n",
    "    Geometries to search from.\n",
    "    gdf2 : geopandas.DataFrame\n",
    "    Geoemtries to be searched.\n",
    "    k_neighbors : int, optional\n",
    "    Number of nearest neighbors. The default is 2.\n",
    "    Returns\n",
    "    -------\n",
    "    gdf_final : geopandas.DataFrame\n",
    "    gdf1 with distance, index and all other columns from gdf2.'''\n",
    "\n",
    "    src_points = [(x,y) for x,y in zip(gdf1.geometry.x , gdf1.geometry.y)]\n",
    "    candidates =  [(x,y) for x,y in zip(gdf2.geometry.x , gdf2.geometry.y)]\n",
    "\n",
    "    # Create tree from the candidate points\n",
    "    tree = BallTree(candidates, leaf_size=15, metric='euclidean')\n",
    "\n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "\n",
    "    # Transpose to get distances and indices into arrays\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    closest_gdfs = []\n",
    "    for k in np.arange(k_neighbors):\n",
    "        gdf_new = gdf2.iloc[indices[k]].reset_index()\n",
    "        gdf_new['distance'] =  distances[k]\n",
    "        gdf_new = gdf_new.add_suffix(f'_{k+1}')\n",
    "        closest_gdfs.append(gdf_new)\n",
    "    \n",
    "    closest_gdfs.insert(0,gdf1)    \n",
    "    gdf_final = pd.concat(closest_gdfs,axis=1)\n",
    "\n",
    "    return gdf_final\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    # Create the ID2 column\n",
    "    df[\"ID2\"] = df.index\n",
    "\n",
    "    # Reshape the dataframe from wide to long format using the provided suffix\n",
    "    long_df = pd.wide_to_long(df, stubnames=[\"distance_\", \"index_\", \"geometry_\"], i=\"ID2\", j=\"neighbor\")\n",
    "\n",
    "    # Rename columns\n",
    "    long_df.loc[:, 'origin'] = long_df['ID']\n",
    "    long_df.loc[:, 'dest'] = long_df['index_']\n",
    "    long_df.loc[:, 'euclidean'] = long_df['distance_']\n",
    "\n",
    "    # Reset index and keep necessary columns\n",
    "    long_df = long_df.reset_index(level=\"neighbor\")\n",
    "    cost_df = long_df[['euclidean', 'origin', 'dest', 'neighbor']]\n",
    "\n",
    "    # Sort the dataframe by origin and euclidean distance\n",
    "    cost_df.sort_values(by=['origin', 'euclidean'], inplace=True)\n",
    "\n",
    "    return cost_df\n",
    "\n",
    "def access_measure(df_cost, df_sv, upper, decay):\n",
    "    # Calculate time from euclidean distance\n",
    "    # https://journals-sagepub-com.may.idm.oclc.org/doi/10.1177/0265813516641685\n",
    "    df_cost['time'] = (df_cost['euclidean'] * 3600) / 5000  # convert distance into time (rate of 5kph)\n",
    "    \n",
    "    # Calculate LogitT_5 using the provided formula\n",
    "    df_cost['LogitT_5'] = 1 - (1 / (np.exp((upper / 180) - decay * df_cost['time']) + 1))\n",
    "    \n",
    "    # Sum weighted distances by tract (origin) ID\n",
    "    cost_sum = df_cost.groupby(\"origin\").sum()\n",
    "    cost_sum['ID'] = cost_sum.index\n",
    "    \n",
    "    # Merge with the corresponding smaller sv original dataframe\n",
    "    cost_merge = df_sv.merge(cost_sum, how='inner', on='ID')\n",
    "    \n",
    "    return cost_merge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a350761-7dc4-4f9a-827d-28cb024ed941",
   "metadata": {},
   "source": [
    "## Create the function to process the data from years 1997-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad605b68-0c56-4fd8-8b97-7a24eb789194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_business_data(year):\n",
    "    # Load data for the specified year\n",
    "    gz_file_path = f'../data/InfoUSA Data/{year}/{year}_Business_Academic_QCQ.txt.gz'\n",
    "    \n",
    "    # Open the gzipped file and read its content\n",
    "    with gzip.open(gz_file_path, 'rt', encoding='latin-1') as f:\n",
    "        df = pd.read_csv(f, sep=\",\", encoding='latin-1')\n",
    "\n",
    "    # Amenities: groceries, restaurants, coffee shops, banks, parks, schools, bookstores, entertainment, and general shopping establishments \n",
    "    #schools (https://nces.ed.gov/programs/edge/geographic/schoollocations) and parks (centroids - https://www.arcgis.com/home/item.html?id=f092c20803a047cba81fbf1e30eff0b5)\n",
    "\n",
    "    #Convert the column to string\n",
    "    df['Primary NAICS Code'].astype(str)\n",
    "\n",
    "    #Created new categories of NAICS codes so it was easier to filter the categories of interest.\n",
    "    df['NAICS'] = df['Primary NAICS Code'].astype(str)\n",
    "    df['NAICS2'] = df.NAICS.str[:2]\n",
    "    df['NAICS4'] = df.NAICS.str[:4]\n",
    "    df['NAICS6'] = df.NAICS.str[:6]\n",
    "    df.NAICS4.value_counts()\n",
    "\n",
    "    # Filter by specific amenity NAICS codes\n",
    "\n",
    "    filtered = df.loc[(df['NAICS2'] == '72') | (df['NAICS4'] == '4421') | (df['NAICS4'] == '4431') | (df['NAICS4'] == '4451') | \n",
    "                    (df['NAICS4'] == '4461') | (df['NAICS4'] == '4481') | (df['NAICS4'] == '4482') | (df['NAICS4'] == '4483') |\n",
    "                    (df['NAICS4'] == '4511') | (df['NAICS4'] == '4531') | (df['NAICS4'] == '4532') | (df['NAICS4'] == '4539') |\n",
    "                    (df['NAICS4'] == '4453') | (df['NAICS4'] == '4523') | (df['NAICS4'] == '5221') | (df['NAICS6'] == '311811') |\n",
    "                    (df['NAICS6'] == '451211')]\n",
    "\n",
    "    # Remove Puerto Rico, Alaska, Hawaii, and US Virgin Islands because we will be measuring distances and islands will affect our analysis\n",
    "    filtered = filtered[(filtered['State'] != 'PR') & (filtered['State'] != 'AK') & (filtered['State'] != 'HI') & (filtered['State'] != 'VI')]\n",
    "\n",
    "    # Making sure that the latitude and longitude include all decimal points. # Is this right?\n",
    "    filtered = filtered[filtered.Longitude != '-000.000-76']\n",
    "    filtered = filtered[filtered.Latitude != '-000.000-76']\n",
    "\n",
    "    # Create a geodataframe from coordinates (latitude and longitude)\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        filtered,\n",
    "        geometry=gpd.points_from_xy(filtered.Longitude, filtered.Latitude),\n",
    "        crs='epsg:4326') # epsg specifies the projection\n",
    "\n",
    "        # Change the Coordinate Reference System (CRS)\n",
    "    # Check for different projections here: https://epsg.io/\n",
    "    gdf = gdf.to_crs('esri:102003')\n",
    "\n",
    "    # Make sure that the geometry for each row has a value\n",
    "    gdf = gdf[~gdf.is_empty]\n",
    "\n",
    "    lst=[gdf,sch,prk]\n",
    "    am=pd.concat(lst, ignore_index=True, axis=0)\n",
    "    am[\"ID\"] = am.index\n",
    "\n",
    "    # Keep only the geometry column\n",
    "    am_id = gdf[['geometry']]\n",
    "    am_id\n",
    "\n",
    "    #For 50 NN: #10 seconds\n",
    "    closest50 = get_nearest_neighbors(s_v, am_id, k_neighbors=50)\n",
    "    cost50 = clean_dataframe(closest50)\n",
    "    result50_800 = access_measure(cost50, s_v_filtered, upper=800, decay=.008)\n",
    "\n",
    "\n",
    "    result50_800['ID'] = result50_800['ID'].astype(str)\n",
    "    \n",
    "    # Save the final dataframe to a CSV with the year included in the file name\n",
    "    output_file = f'result50_800_{year}.csv'\n",
    "    output_file = f'../output/result50_800_{year}.csv'\n",
    "    result50_800.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61189e13-145b-4782-813b-edea6f85dbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/2589850904.py:7: DtypeWarning: Columns (24,28,40,42,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\", encoding='latin-1')\n",
      "/Users/kevincredit/opt/anaconda3/envs/geo_env/lib/python3.9/site-packages/geopandas/geodataframe.py:1443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/271410339.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_df.sort_values(by=['origin', 'euclidean'], inplace=True)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/2589850904.py:7: DtypeWarning: Columns (40,42,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\", encoding='latin-1')\n",
      "/Users/kevincredit/opt/anaconda3/envs/geo_env/lib/python3.9/site-packages/geopandas/geodataframe.py:1443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/271410339.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_df.sort_values(by=['origin', 'euclidean'], inplace=True)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/2589850904.py:7: DtypeWarning: Columns (40,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\", encoding='latin-1')\n",
      "/Users/kevincredit/opt/anaconda3/envs/geo_env/lib/python3.9/site-packages/geopandas/geodataframe.py:1443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/271410339.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_df.sort_values(by=['origin', 'euclidean'], inplace=True)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/2589850904.py:7: DtypeWarning: Columns (40,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\", encoding='latin-1')\n",
      "/Users/kevincredit/opt/anaconda3/envs/geo_env/lib/python3.9/site-packages/geopandas/geodataframe.py:1443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/271410339.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_df.sort_values(by=['origin', 'euclidean'], inplace=True)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/2589850904.py:7: DtypeWarning: Columns (10,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\", encoding='latin-1')\n",
      "/Users/kevincredit/opt/anaconda3/envs/geo_env/lib/python3.9/site-packages/geopandas/geodataframe.py:1443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/271410339.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_df.sort_values(by=['origin', 'euclidean'], inplace=True)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/2589850904.py:7: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\", encoding='latin-1')\n",
      "/Users/kevincredit/opt/anaconda3/envs/geo_env/lib/python3.9/site-packages/geopandas/geodataframe.py:1443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/271410339.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_df.sort_values(by=['origin', 'euclidean'], inplace=True)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/2589850904.py:7: DtypeWarning: Columns (10,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\", encoding='latin-1')\n",
      "/Users/kevincredit/opt/anaconda3/envs/geo_env/lib/python3.9/site-packages/geopandas/geodataframe.py:1443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/var/folders/54/0j082m5x2mxcc2wcpp2_glsc0000gn/T/ipykernel_58641/271410339.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_df.sort_values(by=['origin', 'euclidean'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for year in range(1997, 2020):  # Adjust the range as needed\n",
    "    process_business_data(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bafb2c-a134-4785-bfaf-21d6beda4adc",
   "metadata": {},
   "source": [
    "## Merge CSV files into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b890cdb5-dd83-483a-9a60-f0e9d297abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge .csv files\n",
    "def merge_csv_files(csv_path_pattern, start_year, end_year, output_file):\n",
    "    # Initialize an empty DataFrame to hold the merged data\n",
    "    merged_data = None\n",
    "\n",
    "    # Loop through each year\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Generate the CSV file path for the current year\n",
    "        csv_file = csv_path_pattern % year\n",
    "        \n",
    "        # Read the CSV file\n",
    "        csv_data = pd.read_csv(csv_file, dtype={'ID': str})\n",
    "        \n",
    "        # Select the 'ID' and 'LogitT_5' columns and rename 'LogitT_5' to 'WAS{year}'\n",
    "        csv_data = csv_data[['ID', 'LogitT_5']].rename(columns={'LogitT_5': f'WAS{year}'})\n",
    "        \n",
    "        # Merge the current CSV data with the previously merged data\n",
    "        if merged_data is None:\n",
    "            # For the first year, initialize the merged data\n",
    "            merged_data = csv_data\n",
    "        else:\n",
    "            # Merge subsequent years on the 'ID' column\n",
    "            merged_data = pd.merge(merged_data, csv_data, on='ID', how='outer')\n",
    "    \n",
    "    # Save the merged data to a CSV file\n",
    "    merged_data.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc0af86-177c-476b-8b52-0c5f26dacbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "merge_csv_files(\n",
    "  csv_path_pattern = \"../output/result50_800_%d.csv\",  # %d will be replaced by the year\n",
    "  start_year = 1997,\n",
    "  end_year = 2019,\n",
    "    output_file=\"../output/merged_output.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e00978-3200-400d-904a-084c2048e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_csv(\"../output/merged_output.csv\", dtype={'ID': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d38500eb-412c-4548-b550-a4fc21a37e4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>WAS1997</th>\n",
       "      <th>WAS1998</th>\n",
       "      <th>WAS1999</th>\n",
       "      <th>WAS2000</th>\n",
       "      <th>WAS2001</th>\n",
       "      <th>WAS2002</th>\n",
       "      <th>WAS2003</th>\n",
       "      <th>WAS2004</th>\n",
       "      <th>WAS2005</th>\n",
       "      <th>...</th>\n",
       "      <th>WAS2010</th>\n",
       "      <th>WAS2011</th>\n",
       "      <th>WAS2012</th>\n",
       "      <th>WAS2013</th>\n",
       "      <th>WAS2014</th>\n",
       "      <th>WAS2015</th>\n",
       "      <th>WAS2016</th>\n",
       "      <th>WAS2017</th>\n",
       "      <th>WAS2018</th>\n",
       "      <th>WAS2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010010201001</td>\n",
       "      <td>0.286106</td>\n",
       "      <td>0.232622</td>\n",
       "      <td>0.175505</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>0.231888</td>\n",
       "      <td>0.245406</td>\n",
       "      <td>0.304709</td>\n",
       "      <td>0.259122</td>\n",
       "      <td>0.343507</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029205</td>\n",
       "      <td>0.221847</td>\n",
       "      <td>0.209708</td>\n",
       "      <td>1.099580</td>\n",
       "      <td>1.148941</td>\n",
       "      <td>2.080988</td>\n",
       "      <td>2.068950</td>\n",
       "      <td>1.155888</td>\n",
       "      <td>1.114936</td>\n",
       "      <td>1.089932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010010201002</td>\n",
       "      <td>11.971912</td>\n",
       "      <td>10.375749</td>\n",
       "      <td>7.981109</td>\n",
       "      <td>8.779019</td>\n",
       "      <td>4.789293</td>\n",
       "      <td>8.798422</td>\n",
       "      <td>6.431561</td>\n",
       "      <td>8.018477</td>\n",
       "      <td>8.399062</td>\n",
       "      <td>...</td>\n",
       "      <td>4.809486</td>\n",
       "      <td>4.811480</td>\n",
       "      <td>5.613023</td>\n",
       "      <td>10.145084</td>\n",
       "      <td>7.630166</td>\n",
       "      <td>7.992792</td>\n",
       "      <td>5.596471</td>\n",
       "      <td>5.898272</td>\n",
       "      <td>2.705891</td>\n",
       "      <td>5.100125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010010202001</td>\n",
       "      <td>1.372614</td>\n",
       "      <td>1.241583</td>\n",
       "      <td>0.950506</td>\n",
       "      <td>0.763438</td>\n",
       "      <td>0.556322</td>\n",
       "      <td>0.961718</td>\n",
       "      <td>0.753916</td>\n",
       "      <td>1.743156</td>\n",
       "      <td>2.512532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467808</td>\n",
       "      <td>1.280566</td>\n",
       "      <td>1.342089</td>\n",
       "      <td>2.838298</td>\n",
       "      <td>2.719097</td>\n",
       "      <td>2.484229</td>\n",
       "      <td>2.288169</td>\n",
       "      <td>2.342801</td>\n",
       "      <td>2.057829</td>\n",
       "      <td>2.247687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID    WAS1997    WAS1998   WAS1999   WAS2000   WAS2001   WAS2002  \\\n",
       "0  010010201001   0.286106   0.232622  0.175505  0.213228  0.231888  0.245406   \n",
       "1  010010201002  11.971912  10.375749  7.981109  8.779019  4.789293  8.798422   \n",
       "2  010010202001   1.372614   1.241583  0.950506  0.763438  0.556322  0.961718   \n",
       "\n",
       "    WAS2003   WAS2004   WAS2005  ...   WAS2010   WAS2011   WAS2012    WAS2013  \\\n",
       "0  0.304709  0.259122  0.343507  ...  1.029205  0.221847  0.209708   1.099580   \n",
       "1  6.431561  8.018477  8.399062  ...  4.809486  4.811480  5.613023  10.145084   \n",
       "2  0.753916  1.743156  2.512532  ...  0.467808  1.280566  1.342089   2.838298   \n",
       "\n",
       "    WAS2014   WAS2015   WAS2016   WAS2017   WAS2018   WAS2019  \n",
       "0  1.148941  2.080988  2.068950  1.155888  1.114936  1.089932  \n",
       "1  7.630166  7.992792  5.596471  5.898272  2.705891  5.100125  \n",
       "2  2.719097  2.484229  2.288169  2.342801  2.057829  2.247687  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b11b9-7d50-4097-9fc2-1ff0355d02da",
   "metadata": {},
   "source": [
    "## Merge CSV with block group shapefile (s_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "493ce323-2c57-46ff-b7cb-f74d6132f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_shapefile_data = s_v_filtered.merge(merged_data, on='ID', how='left')\n",
    "\n",
    "#Adding geometry column to the end\n",
    "columns = [col for col in final_shapefile_data.columns if col != 'geometry'] + ['geometry']\n",
    "final_shapefile_data = final_shapefile_data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48791038-9a2f-4c32-8c81-fdb4834b6518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>WAS1997</th>\n",
       "      <th>WAS1998</th>\n",
       "      <th>WAS1999</th>\n",
       "      <th>WAS2000</th>\n",
       "      <th>WAS2001</th>\n",
       "      <th>WAS2002</th>\n",
       "      <th>WAS2003</th>\n",
       "      <th>WAS2004</th>\n",
       "      <th>WAS2005</th>\n",
       "      <th>...</th>\n",
       "      <th>WAS2011</th>\n",
       "      <th>WAS2012</th>\n",
       "      <th>WAS2013</th>\n",
       "      <th>WAS2014</th>\n",
       "      <th>WAS2015</th>\n",
       "      <th>WAS2016</th>\n",
       "      <th>WAS2017</th>\n",
       "      <th>WAS2018</th>\n",
       "      <th>WAS2019</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060014001001</td>\n",
       "      <td>0.583724</td>\n",
       "      <td>0.355387</td>\n",
       "      <td>0.436912</td>\n",
       "      <td>0.388209</td>\n",
       "      <td>0.343679</td>\n",
       "      <td>0.348998</td>\n",
       "      <td>1.094018</td>\n",
       "      <td>1.140027</td>\n",
       "      <td>0.674874</td>\n",
       "      <td>...</td>\n",
       "      <td>1.327219</td>\n",
       "      <td>2.365213</td>\n",
       "      <td>2.593814</td>\n",
       "      <td>2.484240</td>\n",
       "      <td>1.686187</td>\n",
       "      <td>1.770627</td>\n",
       "      <td>1.965558</td>\n",
       "      <td>2.104157</td>\n",
       "      <td>1.501614</td>\n",
       "      <td>POINT (-2256868.242 354675.748)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>060014002001</td>\n",
       "      <td>45.558356</td>\n",
       "      <td>45.508242</td>\n",
       "      <td>46.032436</td>\n",
       "      <td>45.879307</td>\n",
       "      <td>45.746954</td>\n",
       "      <td>45.860761</td>\n",
       "      <td>46.001192</td>\n",
       "      <td>46.065448</td>\n",
       "      <td>46.013966</td>\n",
       "      <td>...</td>\n",
       "      <td>45.916184</td>\n",
       "      <td>46.231157</td>\n",
       "      <td>46.261229</td>\n",
       "      <td>46.375803</td>\n",
       "      <td>46.251646</td>\n",
       "      <td>46.356328</td>\n",
       "      <td>46.268897</td>\n",
       "      <td>46.213793</td>\n",
       "      <td>46.196294</td>\n",
       "      <td>POINT (-2258832.974 353148.920)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>060014002002</td>\n",
       "      <td>47.594279</td>\n",
       "      <td>47.550773</td>\n",
       "      <td>47.583356</td>\n",
       "      <td>47.725176</td>\n",
       "      <td>47.550251</td>\n",
       "      <td>47.621034</td>\n",
       "      <td>47.666230</td>\n",
       "      <td>47.715238</td>\n",
       "      <td>47.779969</td>\n",
       "      <td>...</td>\n",
       "      <td>47.538293</td>\n",
       "      <td>47.663359</td>\n",
       "      <td>47.572320</td>\n",
       "      <td>47.603393</td>\n",
       "      <td>47.351799</td>\n",
       "      <td>47.569731</td>\n",
       "      <td>47.627022</td>\n",
       "      <td>47.550301</td>\n",
       "      <td>47.554087</td>\n",
       "      <td>POINT (-2259050.925 352843.123)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID    WAS1997    WAS1998    WAS1999    WAS2000    WAS2001  \\\n",
       "0  060014001001   0.583724   0.355387   0.436912   0.388209   0.343679   \n",
       "1  060014002001  45.558356  45.508242  46.032436  45.879307  45.746954   \n",
       "2  060014002002  47.594279  47.550773  47.583356  47.725176  47.550251   \n",
       "\n",
       "     WAS2002    WAS2003    WAS2004    WAS2005  ...    WAS2011    WAS2012  \\\n",
       "0   0.348998   1.094018   1.140027   0.674874  ...   1.327219   2.365213   \n",
       "1  45.860761  46.001192  46.065448  46.013966  ...  45.916184  46.231157   \n",
       "2  47.621034  47.666230  47.715238  47.779969  ...  47.538293  47.663359   \n",
       "\n",
       "     WAS2013    WAS2014    WAS2015    WAS2016    WAS2017    WAS2018  \\\n",
       "0   2.593814   2.484240   1.686187   1.770627   1.965558   2.104157   \n",
       "1  46.261229  46.375803  46.251646  46.356328  46.268897  46.213793   \n",
       "2  47.572320  47.603393  47.351799  47.569731  47.627022  47.550301   \n",
       "\n",
       "     WAS2019                         geometry  \n",
       "0   1.501614  POINT (-2256868.242 354675.748)  \n",
       "1  46.196294  POINT (-2258832.974 353148.920)  \n",
       "2  47.554087  POINT (-2259050.925 352843.123)  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_shapefile_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d33aa3ee-1c4d-45b1-8e38-b322e46bab33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215831"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_shapefile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0b28542-cbd4-4352-98f6-1812713cca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write shapefile to the output folder\n",
    "final_shapefile_data.to_file(filename='../output/US_WAS_1997_2019.shp.zip',\n",
    "                             driver='ESRI Shapefile',\n",
    "                             compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11cac3b4-4199-4b8c-869a-ec4ec8774b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7738.431283209"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed = timeit.default_timer() - start_time\n",
    "elapsed\n",
    "# Approximately 129 minutes, a little bit more than 2 hours."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
