{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e4aaea0-a910-4a3e-8abd-f6e29eb52a1c",
   "metadata": {},
   "source": [
    "# Walkable Accessibility Score for Years 1997 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "568a43f8-246c-4f68-a3bb-35ed55a06e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this cell to time how long it takes to run the notebook\n",
    "\n",
    "import timeit\n",
    "start_time = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb916934-c6a3-4082-b3be-16aecc13f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(1, '/users/ifarah/appdata/roaming/python/python39/site-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63adbb9-8811-47b3-b6de-6fb335954b8c",
   "metadata": {},
   "source": [
    "We must specify the correct directory path to load some packages. In the code below, REPLACE 'ifarah' with your personal username. It should be shown in the output directories of the installed packages above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0badfdb7-6f98-42ba-9256-e803dce0c7bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.neighbors import BallTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from scipy import stats # for correlation\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111d305f-4d35-4645-9b30-5e67dbc7fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only have to read once\n",
    "# Read in the 2015 Block Group Shapefile for all the US.\n",
    "s_v = gpd.read_file('../data/2015_US_BG/BG_mainland.shp') # Load geography (oftentimes as shapefile).\n",
    "\n",
    "# Add 2011 GreatSchools school data\n",
    "sch = gpd.read_file('../data/GreatSchools_2011_us48/GreatSchools_2011_us48.shp') \n",
    "sch = sch.to_crs('esri:102003')\n",
    "\n",
    "#2021 ESRI parks data (centroids)\n",
    "prk = gpd.read_file('../data/Centroids_for_USA_Parks_2021/parks2.shp') \n",
    "prk = prk.to_crs('esri:102003')\n",
    "\n",
    "# Change the Coordinate Reference System\n",
    "s_v = s_v.set_crs('esri:102003', allow_override=True) # Set the Coordinate Reference System\n",
    "s_v.rename(columns={'GEOID': 'ID'}, inplace=True) # Rename the columns for convenience\n",
    "\n",
    "# Extract the centroids of the polygons.\n",
    "# Replace the column \"geometry\" with the centroids of geography.\n",
    "# This will change the geometry from \"polygon\" to \"point\" geometry.\n",
    "s_v['geometry'] = s_v.centroid\n",
    "\n",
    "s_v_filtered = s_v[['ID', 'geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336fc330-ce51-457d-b2c2-70bd5c9cc6d1",
   "metadata": {},
   "source": [
    "## Create functions to run the walkable accessibility score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b929c6c8-7c48-4311-a364-f9b106b62129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is creating a function for eastimating nearest neighbors from point to point.\n",
    "def get_nearest_neighbors(gdf1, gdf2, k_neighbors=2):\n",
    "    '''Find k nearest neighbors for all source points from a set of candidate points\n",
    "    modified from: https://automating-gis-processes.github.io/site/notebooks/L3/nearest-neighbor-faster.html    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf1 : geopandas.DataFrame\n",
    "    Geometries to search from.\n",
    "    gdf2 : geopandas.DataFrame\n",
    "    Geoemtries to be searched.\n",
    "    k_neighbors : int, optional\n",
    "    Number of nearest neighbors. The default is 2.\n",
    "    Returns\n",
    "    -------\n",
    "    gdf_final : geopandas.DataFrame\n",
    "    gdf1 with distance, index and all other columns from gdf2.'''\n",
    "\n",
    "    src_points = [(x,y) for x,y in zip(gdf1.geometry.x , gdf1.geometry.y)]\n",
    "    candidates =  [(x,y) for x,y in zip(gdf2.geometry.x , gdf2.geometry.y)]\n",
    "\n",
    "    # Create tree from the candidate points\n",
    "    tree = BallTree(candidates, leaf_size=15, metric='euclidean')\n",
    "\n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "\n",
    "    # Transpose to get distances and indices into arrays\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    closest_gdfs = []\n",
    "    for k in np.arange(k_neighbors):\n",
    "        gdf_new = gdf2.iloc[indices[k]].reset_index()\n",
    "        gdf_new['distance'] =  distances[k]\n",
    "        gdf_new = gdf_new.add_suffix(f'_{k+1}')\n",
    "        closest_gdfs.append(gdf_new)\n",
    "    \n",
    "    closest_gdfs.insert(0,gdf1)    \n",
    "    gdf_final = pd.concat(closest_gdfs,axis=1)\n",
    "\n",
    "    return gdf_final\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    # Create the ID2 column\n",
    "    df[\"ID2\"] = df.index\n",
    "\n",
    "    # Reshape the dataframe from wide to long format using the provided suffix\n",
    "    long_df = pd.wide_to_long(df, stubnames=[\"distance_\", \"index_\", \"geometry_\", \"types_weights_\"], i=\"ID2\", j=\"neighbor\") #Irene\n",
    "\n",
    "    # Rename columns\n",
    "    long_df.loc[:, 'origin'] = long_df['ID']\n",
    "    long_df.loc[:, 'dest'] = long_df['index_']\n",
    "    long_df.loc[:, 'euclidean'] = long_df['distance_']\n",
    "    long_df.loc[:, 'weights'] = long_df['types_weights_'] \n",
    "\n",
    "    # Reset index and keep necessary columns\n",
    "    long_df = long_df.reset_index(level=\"neighbor\")\n",
    "    cost_df = long_df[['euclidean', 'origin', 'dest', 'neighbor', 'weights']] \n",
    "\n",
    "    # Sort the dataframe by origin and euclidean distance\n",
    "    cost_df.sort_values(by=['origin', 'euclidean'], inplace=True)\n",
    "\n",
    "    return cost_df\n",
    "    \n",
    "def access_measure(df_cost, df_sv, upper, decay):\n",
    "    # Calculate time from euclidean distance\n",
    "    # https://journals-sagepub-com.may.idm.oclc.org/doi/10.1177/0265813516641685\n",
    "    df_cost['time'] = (df_cost['euclidean'] * 3600) / 5000  # convert distance into time (rate of 5kph)\n",
    "    \n",
    "    # Calculate LogitT_5 using the provided formula\n",
    "    df_cost['LogitT_5'] = 1 - (1 / (np.exp((upper / 180) - decay * df_cost['time']) + 1))\n",
    "    \n",
    "    # Apply weights to the accessibility score\n",
    "    df_cost['weighted_access'] = df_cost['LogitT_5'] * df_cost['weights']\n",
    "    \n",
    "    # Sum weighted distances by tract (origin) ID\n",
    "    cost_sum = df_cost.groupby(\"origin\").sum()\n",
    "    cost_sum['ID'] = cost_sum.index\n",
    "    \n",
    "    # Merge with the corresponding smaller sv original dataframe\n",
    "    cost_merge = df_sv.merge(cost_sum, how='inner', on='ID')\n",
    "    \n",
    "    # If you wanâ€™t do standarize the score, you can include code here\n",
    "    \n",
    "    return cost_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a350761-7dc4-4f9a-827d-28cb024ed941",
   "metadata": {},
   "source": [
    "## Create the function to process the data from years 1997-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad605b68-0c56-4fd8-8b97-7a24eb789194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_business_data(year):\n",
    "    # Load data for the specified year\n",
    "    gz_file_path = f'../data/InfoUSA Data/{year}/{year}_Business_Academic_QCQ.txt.gz'\n",
    "    \n",
    "    # Open the gzipped file and read its content\n",
    "    with gzip.open(gz_file_path, 'rt', encoding='latin-1') as f:\n",
    "        df = pd.read_csv(f, sep=\",\", encoding='latin-1')\n",
    "\n",
    "    # Amenities: groceries, restaurants, coffee shops, banks, parks, schools, bookstores, entertainment, and general shopping establishments \n",
    "    #schools (https://nces.ed.gov/programs/edge/geographic/schoollocations) and parks (centroids - https://www.arcgis.com/home/item.html?id=f092c20803a047cba81fbf1e30eff0b5)\n",
    "\n",
    "    #Convert the column to string\n",
    "    df['Primary NAICS Code'].astype(str)\n",
    "\n",
    "    #Created new categories of NAICS codes so it was easier to filter the categories of interest.\n",
    "    df['NAICS'] = df['Primary NAICS Code'].astype(str)\n",
    "    df['NAICS2'] = df.NAICS.str[:2]\n",
    "    df['NAICS4'] = df.NAICS.str[:4]\n",
    "    df['NAICS6'] = df.NAICS.str[:6]\n",
    "    df.NAICS4.value_counts()\n",
    "\n",
    "    # Filter by specific amenity NAICS codes\n",
    "\n",
    "    filtered = df.loc[(df['NAICS2'] == '72') | (df['NAICS4'] == '4421') | (df['NAICS4'] == '4431') | (df['NAICS4'] == '4451') | \n",
    "                    (df['NAICS4'] == '4461') | (df['NAICS4'] == '4481') | (df['NAICS4'] == '4482') | (df['NAICS4'] == '4483') |\n",
    "                    (df['NAICS4'] == '4511') | (df['NAICS4'] == '4531') | (df['NAICS4'] == '4532') | (df['NAICS4'] == '4539') |\n",
    "                    (df['NAICS4'] == '4453') | (df['NAICS4'] == '4523') | (df['NAICS4'] == '5221') | (df['NAICS6'] == '311811') |\n",
    "                    (df['NAICS6'] == '451211')]\n",
    "\n",
    "    # Remove Puerto Rico, Alaska, Hawaii, and US Virgin Islands because we will be measuring distances and islands will affect our analysis\n",
    "    filtered = filtered[(filtered['State'] != 'PR') & (filtered['State'] != 'AK') & (filtered['State'] != 'HI') & (filtered['State'] != 'VI')]\n",
    "\n",
    "    # Making sure that the latitude and longitude include all decimal points. # Is this right?\n",
    "    filtered = filtered[filtered.Longitude != '-000.000-76']\n",
    "    filtered = filtered[filtered.Latitude != '-000.000-76']\n",
    "\n",
    "    # Mapping values (you can change the assignments as needed)\n",
    "    # Function to assign weights with a default of 1\n",
    "    def assign_weights(type, mapping=None):\n",
    "        if mapping is None:\n",
    "            mapping = {}  # Default to empty dict\n",
    "            return mapping.get(type, 1)  # Return mapped value or default to 1\n",
    "\n",
    "    # Example. Change NAICS2 according to whatever your type of destination values are. In our case, amenities.\n",
    "    filtered['NAICS2'] = filtered['NAICS2'].astype(int)  # Ensure integer type or whatever your category is\n",
    "\n",
    "    #mapping = {72: 1, 44: 2, 45: 0.5, 23: 2, 52:1, 31:2}  # Example mapping for different types of weights\n",
    "    mapping = {} # Defaults the weights to 1\n",
    "\n",
    "    filtered['types_weights'] = filtered['NAICS2'].apply(lambda x: assign_weights(x, mapping))\n",
    "\n",
    "    # Create a geodataframe from coordinates (latitude and longitude)\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        filtered,\n",
    "        geometry=gpd.points_from_xy(filtered.Longitude, filtered.Latitude),\n",
    "        crs='epsg:4326') # epsg specifies the projection\n",
    "\n",
    "        # Change the Coordinate Reference System (CRS)\n",
    "    # Check for different projections here: https://epsg.io/\n",
    "    gdf = gdf.to_crs('esri:102003')\n",
    "\n",
    "    # Make sure that the geometry for each row has a value\n",
    "    gdf = gdf[~gdf.is_empty]\n",
    "\n",
    "    \n",
    "    # For our example, assign equal weights = 1 to parks and schools\n",
    "    sch[\"types_weights\"] = 1\n",
    "    prk[\"types_weights\"] = 1\n",
    "\n",
    "    lst=[gdf,sch,prk]\n",
    "    am=pd.concat(lst, ignore_index=True, axis=0)\n",
    "    am[\"ID\"] = am.index\n",
    "\n",
    "\n",
    "    # Keep only the geometry column\n",
    "    am_id = gdf[['geometry', 'types_weights']]\n",
    "    am_id\n",
    "\n",
    "    #For 30 NN: #10 seconds\n",
    "    closest30 = get_nearest_neighbors(s_v, am_id, k_neighbors=30)\n",
    "    cost30 = clean_dataframe(closest30)\n",
    "    result30_800 = access_measure(cost30, s_v_filtered, upper=800, decay=.008)\n",
    "\n",
    "\n",
    "    result30_800['ID'] = result30_800['ID'].astype(str)\n",
    "    \n",
    "    # Save the final dataframe to a CSV with the year included in the file name\n",
    "    #output_file = f'result30_800_{year}.csv'\n",
    "    output_file = f'../output/historical/result30_800_{year}.csv'\n",
    "    result30_800.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61189e13-145b-4782-813b-edea6f85dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for year in range(1997, 2020):  # Adjust the range as needed\n",
    "    process_business_data(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bafb2c-a134-4785-bfaf-21d6beda4adc",
   "metadata": {},
   "source": [
    "## Merge CSV files into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b890cdb5-dd83-483a-9a60-f0e9d297abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge .csv files\n",
    "def merge_csv_files(csv_path_pattern, start_year, end_year, output_file):\n",
    "    # Initialize an empty DataFrame to hold the merged data\n",
    "    merged_data = None\n",
    "\n",
    "    # Loop through each year\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Generate the CSV file path for the current year\n",
    "        csv_file = csv_path_pattern % year\n",
    "        \n",
    "        # Read the CSV file\n",
    "        csv_data = pd.read_csv(csv_file, dtype={'ID': str})\n",
    "        \n",
    "        # Select the 'ID' and 'LogitT_5' columns and rename 'LogitT_5' to 'WAS{year}'\n",
    "        csv_data = csv_data[['ID', 'LogitT_5']].rename(columns={'LogitT_5': f'WAS{year}'})\n",
    "        \n",
    "        # Merge the current CSV data with the previously merged data\n",
    "        if merged_data is None:\n",
    "            # For the first year, initialize the merged data\n",
    "            merged_data = csv_data\n",
    "        else:\n",
    "            # Merge subsequent years on the 'ID' column\n",
    "            merged_data = pd.merge(merged_data, csv_data, on='ID', how='outer')\n",
    "    \n",
    "    # Save the merged data to a CSV file\n",
    "    merged_data.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fc0af86-177c-476b-8b52-0c5f26dacbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "merge_csv_files(\n",
    "  csv_path_pattern = \"../output/historical/result30_800_%d.csv\",  # %d will be replaced by the year\n",
    "  start_year = 1997,\n",
    "  end_year = 2019,\n",
    "    output_file=\"../output/historical/merged_output.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94e00978-3200-400d-904a-084c2048e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_csv(\"../output/historical/merged_output.csv\", dtype={'ID': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d38500eb-412c-4548-b550-a4fc21a37e4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>WAS1997</th>\n",
       "      <th>WAS1998</th>\n",
       "      <th>WAS1999</th>\n",
       "      <th>WAS2000</th>\n",
       "      <th>WAS2001</th>\n",
       "      <th>WAS2002</th>\n",
       "      <th>WAS2003</th>\n",
       "      <th>WAS2004</th>\n",
       "      <th>WAS2005</th>\n",
       "      <th>...</th>\n",
       "      <th>WAS2010</th>\n",
       "      <th>WAS2011</th>\n",
       "      <th>WAS2012</th>\n",
       "      <th>WAS2013</th>\n",
       "      <th>WAS2014</th>\n",
       "      <th>WAS2015</th>\n",
       "      <th>WAS2016</th>\n",
       "      <th>WAS2017</th>\n",
       "      <th>WAS2018</th>\n",
       "      <th>WAS2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010010201001</td>\n",
       "      <td>0.258136</td>\n",
       "      <td>0.230324</td>\n",
       "      <td>0.175452</td>\n",
       "      <td>0.210601</td>\n",
       "      <td>0.231883</td>\n",
       "      <td>0.242781</td>\n",
       "      <td>0.284502</td>\n",
       "      <td>0.244252</td>\n",
       "      <td>0.309237</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023865</td>\n",
       "      <td>0.214626</td>\n",
       "      <td>0.205132</td>\n",
       "      <td>1.059284</td>\n",
       "      <td>1.128294</td>\n",
       "      <td>2.049235</td>\n",
       "      <td>2.050134</td>\n",
       "      <td>1.135954</td>\n",
       "      <td>1.111210</td>\n",
       "      <td>1.084975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010010201002</td>\n",
       "      <td>11.971906</td>\n",
       "      <td>10.375748</td>\n",
       "      <td>7.981109</td>\n",
       "      <td>8.779018</td>\n",
       "      <td>4.789293</td>\n",
       "      <td>8.798421</td>\n",
       "      <td>6.431556</td>\n",
       "      <td>8.018473</td>\n",
       "      <td>8.399056</td>\n",
       "      <td>...</td>\n",
       "      <td>4.809483</td>\n",
       "      <td>4.811476</td>\n",
       "      <td>5.613020</td>\n",
       "      <td>10.145072</td>\n",
       "      <td>7.630156</td>\n",
       "      <td>7.992783</td>\n",
       "      <td>5.596465</td>\n",
       "      <td>5.898265</td>\n",
       "      <td>2.705890</td>\n",
       "      <td>5.100122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010010202001</td>\n",
       "      <td>1.370488</td>\n",
       "      <td>1.240972</td>\n",
       "      <td>0.950237</td>\n",
       "      <td>0.762860</td>\n",
       "      <td>0.556141</td>\n",
       "      <td>0.960884</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>1.741759</td>\n",
       "      <td>2.510242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466609</td>\n",
       "      <td>1.279072</td>\n",
       "      <td>1.341113</td>\n",
       "      <td>2.834827</td>\n",
       "      <td>2.715764</td>\n",
       "      <td>2.481719</td>\n",
       "      <td>2.286432</td>\n",
       "      <td>2.340673</td>\n",
       "      <td>2.056937</td>\n",
       "      <td>2.246366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID    WAS1997    WAS1998   WAS1999   WAS2000   WAS2001   WAS2002  \\\n",
       "0  010010201001   0.258136   0.230324  0.175452  0.210601  0.231883  0.242781   \n",
       "1  010010201002  11.971906  10.375748  7.981109  8.779018  4.789293  8.798421   \n",
       "2  010010202001   1.370488   1.240972  0.950237  0.762860  0.556141  0.960884   \n",
       "\n",
       "    WAS2003   WAS2004   WAS2005  ...   WAS2010   WAS2011   WAS2012    WAS2013  \\\n",
       "0  0.284502  0.244252  0.309237  ...  1.023865  0.214626  0.205132   1.059284   \n",
       "1  6.431556  8.018473  8.399056  ...  4.809483  4.811476  5.613020  10.145072   \n",
       "2  0.751901  1.741759  2.510242  ...  0.466609  1.279072  1.341113   2.834827   \n",
       "\n",
       "    WAS2014   WAS2015   WAS2016   WAS2017   WAS2018   WAS2019  \n",
       "0  1.128294  2.049235  2.050134  1.135954  1.111210  1.084975  \n",
       "1  7.630156  7.992783  5.596465  5.898265  2.705890  5.100122  \n",
       "2  2.715764  2.481719  2.286432  2.340673  2.056937  2.246366  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b11b9-7d50-4097-9fc2-1ff0355d02da",
   "metadata": {},
   "source": [
    "## Merge CSV with block group shapefile (s_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "493ce323-2c57-46ff-b7cb-f74d6132f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_shapefile_data = s_v_filtered.merge(merged_data, on='ID', how='left')\n",
    "\n",
    "#Adding geometry column to the end\n",
    "columns = [col for col in final_shapefile_data.columns if col != 'geometry'] + ['geometry']\n",
    "final_shapefile_data = final_shapefile_data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48791038-9a2f-4c32-8c81-fdb4834b6518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>WAS1997</th>\n",
       "      <th>WAS1998</th>\n",
       "      <th>WAS1999</th>\n",
       "      <th>WAS2000</th>\n",
       "      <th>WAS2001</th>\n",
       "      <th>WAS2002</th>\n",
       "      <th>WAS2003</th>\n",
       "      <th>WAS2004</th>\n",
       "      <th>WAS2005</th>\n",
       "      <th>...</th>\n",
       "      <th>WAS2011</th>\n",
       "      <th>WAS2012</th>\n",
       "      <th>WAS2013</th>\n",
       "      <th>WAS2014</th>\n",
       "      <th>WAS2015</th>\n",
       "      <th>WAS2016</th>\n",
       "      <th>WAS2017</th>\n",
       "      <th>WAS2018</th>\n",
       "      <th>WAS2019</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060014001001</td>\n",
       "      <td>0.572791</td>\n",
       "      <td>0.345769</td>\n",
       "      <td>0.425540</td>\n",
       "      <td>0.378639</td>\n",
       "      <td>0.334923</td>\n",
       "      <td>0.339709</td>\n",
       "      <td>1.084540</td>\n",
       "      <td>1.130749</td>\n",
       "      <td>0.659183</td>\n",
       "      <td>...</td>\n",
       "      <td>1.289337</td>\n",
       "      <td>2.255641</td>\n",
       "      <td>2.400871</td>\n",
       "      <td>2.367166</td>\n",
       "      <td>1.598406</td>\n",
       "      <td>1.695073</td>\n",
       "      <td>1.803503</td>\n",
       "      <td>2.031648</td>\n",
       "      <td>1.483406</td>\n",
       "      <td>POINT (-2256868.242 354675.748)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>060014002001</td>\n",
       "      <td>27.929052</td>\n",
       "      <td>27.917758</td>\n",
       "      <td>28.077785</td>\n",
       "      <td>28.016131</td>\n",
       "      <td>28.013816</td>\n",
       "      <td>28.012159</td>\n",
       "      <td>28.051093</td>\n",
       "      <td>28.056821</td>\n",
       "      <td>28.030875</td>\n",
       "      <td>...</td>\n",
       "      <td>27.959644</td>\n",
       "      <td>28.062716</td>\n",
       "      <td>28.068900</td>\n",
       "      <td>28.099463</td>\n",
       "      <td>28.075069</td>\n",
       "      <td>28.107066</td>\n",
       "      <td>28.057852</td>\n",
       "      <td>28.051671</td>\n",
       "      <td>28.005370</td>\n",
       "      <td>POINT (-2258832.974 353148.920)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>060014002002</td>\n",
       "      <td>29.001909</td>\n",
       "      <td>28.977535</td>\n",
       "      <td>28.974707</td>\n",
       "      <td>29.041400</td>\n",
       "      <td>28.974401</td>\n",
       "      <td>29.001840</td>\n",
       "      <td>29.036504</td>\n",
       "      <td>29.045935</td>\n",
       "      <td>29.081158</td>\n",
       "      <td>...</td>\n",
       "      <td>29.003727</td>\n",
       "      <td>29.030480</td>\n",
       "      <td>28.946564</td>\n",
       "      <td>28.963787</td>\n",
       "      <td>28.837081</td>\n",
       "      <td>28.967123</td>\n",
       "      <td>28.961285</td>\n",
       "      <td>28.952694</td>\n",
       "      <td>28.940575</td>\n",
       "      <td>POINT (-2259050.925 352843.123)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID    WAS1997    WAS1998    WAS1999    WAS2000    WAS2001  \\\n",
       "0  060014001001   0.572791   0.345769   0.425540   0.378639   0.334923   \n",
       "1  060014002001  27.929052  27.917758  28.077785  28.016131  28.013816   \n",
       "2  060014002002  29.001909  28.977535  28.974707  29.041400  28.974401   \n",
       "\n",
       "     WAS2002    WAS2003    WAS2004    WAS2005  ...    WAS2011    WAS2012  \\\n",
       "0   0.339709   1.084540   1.130749   0.659183  ...   1.289337   2.255641   \n",
       "1  28.012159  28.051093  28.056821  28.030875  ...  27.959644  28.062716   \n",
       "2  29.001840  29.036504  29.045935  29.081158  ...  29.003727  29.030480   \n",
       "\n",
       "     WAS2013    WAS2014    WAS2015    WAS2016    WAS2017    WAS2018  \\\n",
       "0   2.400871   2.367166   1.598406   1.695073   1.803503   2.031648   \n",
       "1  28.068900  28.099463  28.075069  28.107066  28.057852  28.051671   \n",
       "2  28.946564  28.963787  28.837081  28.967123  28.961285  28.952694   \n",
       "\n",
       "     WAS2019                         geometry  \n",
       "0   1.483406  POINT (-2256868.242 354675.748)  \n",
       "1  28.005370  POINT (-2258832.974 353148.920)  \n",
       "2  28.940575  POINT (-2259050.925 352843.123)  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_shapefile_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d33aa3ee-1c4d-45b1-8e38-b322e46bab33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215831"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_shapefile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0b28542-cbd4-4352-98f6-1812713cca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write shapefile to the output folder\n",
    "final_shapefile_data.to_file(filename='../output/historical/US_WAS_1997_2019.shp.zip',\n",
    "                             driver='ESRI Shapefile',\n",
    "                             compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11cac3b4-4199-4b8c-869a-ec4ec8774b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7738.431283209"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed = timeit.default_timer() - start_time\n",
    "elapsed\n",
    "# Approximately 129 minutes, a little bit more than 2 hours."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
