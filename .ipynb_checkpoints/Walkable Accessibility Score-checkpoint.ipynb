{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute a Walkable Accessibility Score (WAS) at the block group scale using InfoUSA POI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load POI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 2019 InfoUSA data - other data can be used\n",
    "# bis = pd.read_csv('2019_Business_Academic_QCQ.txt', sep=\",\", encoding='latin-1')\n",
    "\n",
    "bis.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amenities: groceries, restaurants, coffee shops, banks, parks, schools, bookstores, entertainment, and general shopping establishments \n",
    "#schools (https://nces.ed.gov/programs/edge/geographic/schoollocations) and parks (centroids - https://www.arcgis.com/home/item.html?id=f092c20803a047cba81fbf1e30eff0b5)\n",
    "bis['NAICS'] = bis['Primary NAICS Code'].astype(str)\n",
    "bis['NAICS2'] = bis.NAICS.str[:2]\n",
    "bis['NAICS4'] = bis.NAICS.str[:4]\n",
    "bis['NAICS6'] = bis.NAICS.str[:6]\n",
    "bis.NAICS4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific amenity NAICS codes\n",
    "ambis = bis.loc[(bis['NAICS2'] == '72') | (bis['NAICS4'] == '4421') | (bis['NAICS4'] == '4431') | (bis['NAICS4'] == '4451') | \n",
    "                (bis['NAICS4'] == '4461') | (bis['NAICS4'] == '4481') | (bis['NAICS4'] == '4482') | (bis['NAICS4'] == '4483') |\n",
    "                (bis['NAICS4'] == '4511') | (bis['NAICS4'] == '4531') | (bis['NAICS4'] == '4532') | (bis['NAICS4'] == '4539') |\n",
    "                (bis['NAICS4'] == '4453') | (bis['NAICS4'] == '4523') | (bis['NAICS4'] == '5221') | (bis['NAICS6'] == '311811') |\n",
    "                (bis['NAICS6'] == '451211')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambis = ambis[ambis.Longitude != '-000.000-76']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a geodataframe from coordinates\n",
    "gbis = gpd.GeoDataFrame(\n",
    "    ambis, geometry=gpd.points_from_xy(ambis.Longitude, ambis.Latitude), crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove Puerto Rico, Alaska, Hawaii, and US Virgin Islands\n",
    "gbis = gbis[(gbis['State'] != 'PR') & (gbis['State'] != 'AK') & (gbis['State'] != 'HI') & (gbis['State'] != 'VI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set CRS\n",
    "gbis = gbis.to_crs('esri:102003')\n",
    "gbis.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbis = gbis[~gbis.is_empty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2011 GreatSchools school data (can use other sources)\n",
    "sch = gpd.read_file('GreatSchools_2011_us48.shp') \n",
    "sch = sch.to_crs('esri:102003')\n",
    "#2021 ESRI parks data (centroids)\n",
    "prk = gpd.read_file('Centroids_for_USA_Parks_2021_Buffer2.shp') \n",
    "prk = prk.to_crs('esri:102003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[gbis,sch,prk]\n",
    "am=pd.concat(lst, ignore_index=True, axis=0)\n",
    "am[\"ID\"] = am.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_id = am[['geometry']]\n",
    "am_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load block groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block group file we're using in this case - one spatial deifnition of demand units for all time periods\n",
    "s_v = gpd.read_file('BG_2011_2015ADI_us48.shp')\n",
    "s_v = s_v.set_crs('esri:102003', allow_override=True)\n",
    "s_v.rename(columns={'GEOID': 'ID'}, inplace=True)\n",
    "s_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 5 subsets of continental US BGs\n",
    "s_v1 = s_v.iloc[0:43167]\n",
    "s_v1 = s_v1.reset_index(drop=True)\n",
    "s_v2 = s_v.iloc[43167:86333]\n",
    "s_v2 = s_v2.reset_index(drop=True)\n",
    "s_v3 = s_v.iloc[86333:129500]\n",
    "s_v3 = s_v3.reset_index(drop=True)\n",
    "s_v4 = s_v.iloc[129500:172666]\n",
    "s_v4 = s_v4.reset_index(drop=True)\n",
    "s_v5 = s_v.iloc[172666:215834]\n",
    "s_v5 = s_v5.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find number of nearest k POI points to each block group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_neighbors(gdf1, gdf2, k_neighbors=2):\n",
    "    '''Find k nearest neighbors for all source points from a set of candidate points\n",
    "    modified from: https://automating-gis-processes.github.io/site/notebooks/L3/nearest-neighbor-faster.html    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf1 : geopandas.DataFrame\n",
    "    Geometries to search from.\n",
    "    gdf2 : geopandas.DataFrame\n",
    "    Geoemtries to be searched.\n",
    "    k_neighbors : int, optional\n",
    "    Number of nearest neighbors. The default is 2.\n",
    "    Returns\n",
    "    -------\n",
    "    gdf_final : geopandas.DataFrame\n",
    "    gdf1 with distance, index and all other columns from gdf2.'''\n",
    "\n",
    "    src_points = [(x,y) for x,y in zip(gdf1.geometry.x , gdf1.geometry.y)]\n",
    "    candidates =  [(x,y) for x,y in zip(gdf2.geometry.x , gdf2.geometry.y)]\n",
    "\n",
    "    # Create tree from the candidate points\n",
    "    tree = BallTree(candidates, leaf_size=15, metric='euclidean')\n",
    "\n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "\n",
    "    # Transpose to get distances and indices into arrays\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    closest_gdfs = []\n",
    "    for k in np.arange(k_neighbors):\n",
    "        gdf_new = gdf2.iloc[indices[k]].reset_index()\n",
    "        gdf_new['distance'] =  distances[k]\n",
    "        gdf_new = gdf_new.add_suffix(f'_{k+1}')\n",
    "        closest_gdfs.append(gdf_new)\n",
    "    \n",
    "    closest_gdfs.insert(0,gdf1)    \n",
    "    gdf_final = pd.concat(closest_gdfs,axis=1)\n",
    "\n",
    "    return gdf_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find closest k amenities for each BG and get also the distance based on Euclidean distance\n",
    "#whole US subsets\n",
    "closest_am1 = get_nearest_neighbors(s_v1, am_id, k_neighbors=150)\n",
    "closest_am2 = get_nearest_neighbors(s_v2, am_id, k_neighbors=150)\n",
    "closest_am3 = get_nearest_neighbors(s_v3, am_id, k_neighbors=150)\n",
    "closest_am4 = get_nearest_neighbors(s_v4, am_id, k_neighbors=150)\n",
    "closest_am5 = get_nearest_neighbors(s_v5, am_id, k_neighbors=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wide to long\n",
    "#Whole US subsets\n",
    "closest_am1[\"ID2\"] = closest_am1.index\n",
    "closest_l1 = pd.wide_to_long(closest_am1, [\"distance_\",\"index_\",\"geometry_\"], i=\"ID2\", j=\"neighbor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_am2[\"ID2\"] = closest_am2.index\n",
    "closest_l2 = pd.wide_to_long(closest_am2, [\"distance_\",\"index_\",\"geometry_\"], i=\"ID2\", j=\"neighbor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_am3[\"ID2\"] = closest_am3.index\n",
    "closest_l3 = pd.wide_to_long(closest_am3, [\"distance_\",\"index_\",\"geometry_\"], i=\"ID2\", j=\"neighbor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_am4[\"ID2\"] = closest_am4.index\n",
    "closest_l4 = pd.wide_to_long(closest_am4, [\"distance_\",\"index_\",\"geometry_\"], i=\"ID2\", j=\"neighbor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_am5[\"ID2\"] = closest_am5.index\n",
    "closest_l5 = pd.wide_to_long(closest_am5, [\"distance_\",\"index_\",\"geometry_\"], i=\"ID2\", j=\"neighbor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename to 'eucidean', 'origin', 'dest'\n",
    "#whole US subsets\n",
    "closest_l1['origin'] = closest_l1['ID']\n",
    "closest_l1['dest'] = closest_l1['index_']\n",
    "closest_l1['euclidean'] = closest_l1['distance_']\n",
    "closest_l1= closest_l1.reset_index(level=(\"neighbor\",))\n",
    "cost1 = closest_l1[['euclidean', 'origin', 'dest','neighbor']]\n",
    "cost1.sort_values(by=['origin','euclidean'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_l2['origin'] = closest_l2['ID']\n",
    "closest_l2['dest'] = closest_l2['index_']\n",
    "closest_l2['euclidean'] = closest_l2['distance_']\n",
    "closest_l2= closest_l2.reset_index(level=(\"neighbor\",))\n",
    "cost2 = closest_l2[['euclidean', 'origin', 'dest','neighbor']]\n",
    "cost2.sort_values(by=['origin','euclidean'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_l3['origin'] = closest_l3['ID']\n",
    "closest_l3['dest'] = closest_l3['index_']\n",
    "closest_l3['euclidean'] = closest_l3['distance_']\n",
    "closest_l3= closest_l3.reset_index(level=(\"neighbor\",))\n",
    "cost3 = closest_l3[['euclidean', 'origin', 'dest','neighbor']]\n",
    "cost3.sort_values(by=['origin','euclidean'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_l4['origin'] = closest_l4['ID']\n",
    "closest_l4['dest'] = closest_l4['index_']\n",
    "closest_l4['euclidean'] = closest_l4['distance_']\n",
    "closest_l4= closest_l4.reset_index(level=(\"neighbor\",))\n",
    "cost4 = closest_l4[['euclidean', 'origin', 'dest','neighbor']]\n",
    "cost4.sort_values(by=['origin','euclidean'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_l5['origin'] = closest_l5['ID']\n",
    "closest_l5['dest'] = closest_l5['index_']\n",
    "closest_l5['euclidean'] = closest_l5['distance_']\n",
    "closest_l5= closest_l5.reset_index(level=(\"neighbor\",))\n",
    "cost5 = closest_l5[['euclidean', 'origin', 'dest','neighbor']]\n",
    "cost5.sort_values(by=['origin','euclidean'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accessibility measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://journals-sagepub-com.may.idm.oclc.org/doi/10.1177/0265813516641685\n",
    "#convert distance into time (rate of 5kph)\n",
    "cost1['time'] = (cost1.euclidean*3600)/5000\n",
    "cost2['time'] = (cost2.euclidean*3600)/5000\n",
    "cost3['time'] = (cost3.euclidean*3600)/5000\n",
    "cost4['time'] = (cost4.euclidean*3600)/5000\n",
    "cost5['time'] = (cost5.euclidean*3600)/5000\n",
    "\n",
    "# choose 'upper' parameter (for testing)\n",
    "# upper = 800\n",
    "# upper = 1600\n",
    "# upper = 2400\n",
    "\n",
    "# choose decay rate\n",
    "# decay = .005\n",
    "# decay = .008\n",
    "# decay = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost1['LogitT_5'] = 1-(1/(np.e**((upper/180)-decay*cost1.time)+1))\n",
    "cost2['LogitT_5'] = 1-(1/(np.e**((upper/180)-decay*cost2.time)+1))\n",
    "cost3['LogitT_5'] = 1-(1/(np.e**((upper/180)-decay*cost3.time)+1))\n",
    "cost4['LogitT_5'] = 1-(1/(np.e**((upper/180)-decay*cost4.time)+1))\n",
    "cost5['LogitT_5'] = 1-(1/(np.e**((upper/180)-decay*cost5.time)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(cost.LogitT_5, bins=50)\n",
    "# plt.hist(cost1.LogitT_5, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum weighted distances by tract (origin) ID\n",
    "cost_sum1 = cost1.groupby(\"origin\").sum()\n",
    "cost_sum1['ID'] = cost_sum1.index\n",
    "cost_sum2 = cost2.groupby(\"origin\").sum()\n",
    "cost_sum2['ID'] = cost_sum2.index\n",
    "cost_sum3 = cost3.groupby(\"origin\").sum()\n",
    "cost_sum3['ID'] = cost_sum3.index\n",
    "cost_sum4 = cost4.groupby(\"origin\").sum()\n",
    "cost_sum4['ID'] = cost_sum4.index\n",
    "cost_sum5 = cost5.groupby(\"origin\").sum()\n",
    "cost_sum5['ID'] = cost_sum5.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_merge1 = s_v1.merge(cost_sum1, how='inner', on='ID')\n",
    "cost_merge2 = s_v2.merge(cost_sum2, how='inner', on='ID')\n",
    "cost_merge3 = s_v3.merge(cost_sum3, how='inner', on='ID')\n",
    "cost_merge4 = s_v4.merge(cost_sum4, how='inner', on='ID')\n",
    "cost_merge5 = s_v5.merge(cost_sum5, how='inner', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export for given year\n",
    "# cost_merge1.to_file('us_walkability_access_score_2019_1.shp')\n",
    "# cost_merge2.to_file('us_walkability_access_score_2019_2.shp')\n",
    "# cost_merge3.to_file('us_walkability_access_score_2019_3.shp')\n",
    "# cost_merge4.to_file('us_walkability_access_score_2019_4.shp')\n",
    "# cost_merge5.to_file('us_walkability_access_score_2019_5.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
